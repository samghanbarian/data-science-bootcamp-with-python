{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets have been used\n",
    "# ap_2010.csv - Data on AP test results\n",
    "# class_size.csv - Data on class size\n",
    "# demographics.csv - Data on demographics\n",
    "# graduation.csv - Data on graduation outcomes\n",
    "# hs_directory.csv - A directory of high schools\n",
    "# sat_results.csv - Data on SAT scores\n",
    "# survey_all.txt - Data on surveys from all schools\n",
    "# survey_d75.txt - Data on surveys from New York City district 75\n",
    "\n",
    "#reading datasets into a dictionary\n",
    "import pandas as pd\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "data = {}\n",
    "data['ap_2010'] = pd.read_csv('schools/ap_2010.csv')\n",
    "data['class_size'] = pd.read_csv('schools/class_size.csv')\n",
    "data['demographics'] = pd.read_csv('schools/demographics.csv')\n",
    "data['graduation'] = pd.read_csv('schools/graduation.csv')\n",
    "data['hs_directory'] = pd.read_csv('schools/hs_directory.csv')\n",
    "data['sat_results'] = pd.read_csv('schools/sat_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring  dataset dictionary\n",
    "data['sat_results'].head(5)\n",
    "data['sat_results'].info()\n",
    "\n",
    "for k in data.keys():\n",
    "    print(data[k].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in txt files into dataframes and combine them together\n",
    "all_survey = pd.read_csv('schools/survey_all.txt', delimiter = '\\t', encoding = 'windows-1252')\n",
    "d75_survey = pd.read_csv('schools/survey_d75.txt', delimiter = '\\t', encoding = 'windows-1252')\n",
    "survey = pd.concat([all_survey,d75_survey] , axis = 0)\n",
    "survey.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remiving unnecessary columns from the dataset and adding to dataset dict\n",
    "survey['DBN'] = survey['dbn'] #changing to uppercase to match the other dataframes\n",
    "survey = survey.loc[:,[\"DBN\", \"rr_s\", \"rr_t\", \"rr_p\", \"N_s\", \"N_t\", \"N_p\", \"saf_p_11\",\n",
    "                       \"com_p_11\", \"eng_p_11\", \"aca_p_11\", \"saf_t_11\", \"com_t_11\", \"eng_t_11\",\n",
    "                       \"aca_t_11\", \"saf_s_11\", \"com_s_11\", \"eng_s_11\", \"aca_s_11\", \"saf_tot_11\",\n",
    "                       \"com_tot_11\", \"eng_tot_11\", \"aca_tot_11\"]]\n",
    "\n",
    "data['survey'] = survey\n",
    "data['survey'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unifying DBN code in \"Class_size\" and \"hs_history\"\n",
    "hs_directory = data['hs_directory']\n",
    "hs_directory['DBN'] = hs_directory['dbn']\n",
    "class_size = data['class_size']\n",
    "\n",
    "#forming the DBN code from CSD and SCHOOL CODE\n",
    "def change_csd(csd):\n",
    "    csd = str(csd)\n",
    "    if len(csd) < 2:\n",
    "        csd = csd.zfill(2)\n",
    "    \n",
    "    return csd   \n",
    "class_size['padded_csd'] = class_size['CSD'].apply(change_csd)\n",
    "data['hs_directory'] = hs_directory\n",
    "class_size['DBN'] = class_size['padded_csd'] + class_size['SCHOOL CODE']\n",
    "data['class_size'] = class_size\n",
    "data['class_size'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining results for Math Reading and Writing into a SAT result\n",
    "sat_result = data['sat_results']\n",
    "sat_result['SAT Math Avg. Score'] = pd.to_numeric(sat_result['SAT Math Avg. Score'],errors = 'coerce')\n",
    "sat_result['SAT Critical Reading Avg. Score'] = pd.to_numeric(sat_result['SAT Critical Reading Avg. Score'],errors = 'coerce')\n",
    "sat_result['SAT Writing Avg. Score'] = pd.to_numeric(sat_result['SAT Writing Avg. Score'],errors = 'coerce')\n",
    "sat_result['sat_score'] = sat_result['SAT Math Avg. Score'] + sat_result['SAT Critical Reading Avg. Score']+ sat_result['SAT Writing Avg. Score']\n",
    "data['sat_result'] = sat_result\n",
    "data['sat_result'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting latitude and longtitude info for each school\n",
    "import re\n",
    "def coords_lat(str):\n",
    "    lat = re.findall(\"\\(.+\\)\",str)\n",
    "    lat = lat[0].split(',')[0].replace('(','')\n",
    "    return lat\n",
    "\n",
    "hs_directory = data['hs_directory']\n",
    "hs_directory['lat'] = hs_directory['Location 1'].apply(coords_lat)\n",
    "\n",
    "data['hs_directory'] = hs_directory\n",
    "def coords_lon(str):\n",
    "    lon = re.findall(\"\\(.+\\)\",str)\n",
    "    lon = lon[0].split(',')[1].replace(')','')\n",
    "    return lon\n",
    "\n",
    "hs_directory['lon'] = hs_directory['Location 1'].apply(coords_lon)\n",
    "hs_directory['lat'] = pd.to_numeric(hs_directory['lat'], errors='coerce')\n",
    "hs_directory['lon'] = pd.to_numeric(hs_directory['lon'], errors='coerce')\n",
    "data['hs_directory'] = hs_directory\n",
    "data['hs_directory'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
